{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vtecftwy/utseus-dives/blob/main/nbs/dive_1_1_img_classification_clean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf4374f8",
      "metadata": {
        "id": "bf4374f8"
      },
      "source": [
        "<h1>Guided Dive</h1>\n",
        "<h1>Build Your Own Image Classifier with Deep Learning</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1911e1e",
      "metadata": {
        "id": "c1911e1e"
      },
      "source": [
        "# Introduction  \n",
        "This notebook walks you through the key steps of building an image classifier using deep learning, following a process used by practitioners.  \n",
        "\n",
        "Each step includes a brief explanation and the corresponding code to run.  \n",
        "\n",
        "- **Beginners**: Simply run the provided code.  \n",
        "- **Experienced users**: Feel free to modify or write your own code. Don't worry‚Äîyou won‚Äôt damage the original notebook or affect others. If something breaks, just reload the notebook and start fresh.  \n",
        "\n",
        "Follow the steps in order, and by the end, you'll have built your own deep learning model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d635b567",
      "metadata": {
        "id": "d635b567"
      },
      "source": [
        "## Agenda for the guided dive:\n",
        "- üìò **Anatomy of a Deep Learning Application**\n",
        "- üì∑ **Building Your Computer Vision Model**\n",
        "    - üìò Project Introduction\n",
        "    - üë®‚Äçüíª Data Processing, Training and Evaluation\n",
        "    - üë®‚Äçüíª Model Improvement"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b516d855",
      "metadata": {
        "id": "b516d855"
      },
      "source": [
        "# üìò Anatomy of a Deep Learning Application"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7fdafac",
      "metadata": {
        "id": "e7fdafac"
      },
      "source": [
        "The core idea behind machine learning is to use **data** (inputs and solutions) to train a **model**.\n",
        "> <div align=\"center\" width=100%>  <img src=\"http://www.charlier-tang.com/guided-dive/resources/imgs/anatomy_dl_01.svg\" height=160px>  </div>\n",
        "\n",
        "**Deep learning** is one type of supervised machine learning which uses an architecture remotely inspired from biological neurons.\n",
        "> <div align=\"center\" width=100%><img src=\"http://www.charlier-tang.com/guided-dive/resources/imgs/aan-small.jpg\" height=300px></div>\n",
        "\n",
        "In the _training phase_, we use **data**, a specific artificial neural network **architecture** and an **optimization algorithm** to train the **model**. The training process give us learned **parameters**.\n",
        "<div align=\"center\" width=100%><img src=\"http://www.charlier-tang.com/guided-dive/resources/imgs/anatomy_dl_02.svg\" height=160px></div>\n",
        "\n",
        "Once we have a trained model (i.e. an **architecture** with **parameters**), we can use it to make prediction on **new data**.\n",
        "\n",
        "<div align=\"center\" width=100%><img src=\"http://www.charlier-tang.com/guided-dive/resources/imgs/anatomy_dl_03.svg\" height=160px></div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a65728d2",
      "metadata": {
        "id": "a65728d2"
      },
      "source": [
        "## The Library: **fast.ai**  \n",
        "\n",
        "In this guided dive, we‚Äôll use **fast.ai**, a library that offers state-of-the-art deep learning implementations with a simple, high-level API.  \n",
        "\n",
        "Built on **PyTorch** and **Python**, it combines power and ease of use, making deep learning more accessible.  \n",
        "\n",
        "<div align=\"left\" width=100%>  \n",
        "<a href=\"https://www.fast.ai/\">  \n",
        "<img src=\"https://docs.google.com/uc?export=download&id=1A0kmDbMxFXDJ_TVGAku562V2zPiDrX_V\" width=15%>  \n",
        "</a>  \n",
        "</div>  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-SmW3jgkWq81",
      "metadata": {
        "id": "-SmW3jgkWq81"
      },
      "source": [
        "## Steps to Train a Model  \n",
        "\n",
        "1. **Collect and prepare data** ‚Äì Ensure the data is ready for the model to learn from.  \n",
        "2. **Select an architecture** ‚Äì Choose a model structure suited to the task.  \n",
        "3. **Train the model** ‚Äì Feed data into the model and apply **transfer learning** to improve performance.  \n",
        "\n",
        "We will walk through each step in detail.**The steps to train a model include:**\n",
        "1. **Collecting the data and preparing them so that the model can learn from them**\n",
        "2. **Selecting an architecture and creating a specific model using that architecture**\n",
        "3. **Training the model by \"feeding\" the data to the model. We will apply transfer learning**\n",
        "\n",
        "We will go through each of these steps."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50e0c1de",
      "metadata": {
        "id": "50e0c1de"
      },
      "source": [
        "#### üîé Details on how each step is structured in the code (optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab30684d",
      "metadata": {
        "id": "ab30684d"
      },
      "source": [
        "\n",
        "1. Collecting the data: `DataBlock()`\n",
        "    - defines what type of data, e.g. `ImageBlock` and `CategoryBlock`\n",
        "    - define how the data is collected, e.g. get the image from a function that will look into a folder the return any image file\n",
        "    - define how to get the label names, e.g. class name/label name is the name of the folder where the images are\n",
        "    - some preprocessing to do for each image, e.g. resizing then all to a square image or fixed value\n",
        "```\n",
        "    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
        "                    get_items=get_image_files,\n",
        "                    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
        "                    get_y=parent_label,\n",
        "                    item_tfms=Resize(128)\n",
        "                    )\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "947315e1",
      "metadata": {
        "id": "947315e1"
      },
      "source": [
        "2. Indicate where the data are, e.g. a path to a specific folder: `dataloaders()`\n",
        "```\n",
        "dls = dblock.dataloaders(path)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cdd6f5e",
      "metadata": {
        "id": "0cdd6f5e"
      },
      "source": [
        "3. Create a model\n",
        "    - select a specific architecture (for image, CNN Resnet with 18 layers)\n",
        "    - in this case we use a pretrained model for general images\n",
        "    - use the data loaders created aboce `dls`\n",
        "    - specify metrics to see how the training evolve\n",
        "```\n",
        "learn = cnn_learner(dls, resnet18, metrics=[accuracy, Recall(), Precision()])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef077693",
      "metadata": {
        "id": "ef077693"
      },
      "source": [
        "4. Train the model\n",
        "    - train it for a given number of iterations (epochs)\n",
        "    - we have a pretrained model, so we only need to fine tune it\n",
        "```\n",
        "learn.fine_tune(5)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90403b1e",
      "metadata": {
        "id": "90403b1e"
      },
      "source": [
        "#### üîé End of details"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5873f103",
      "metadata": {
        "id": "5873f103"
      },
      "source": [
        "#### üîé How to create your own notebook and execute code?\n",
        "If you are not familiar with Colab or hosted Jupyter notebooks, read this section."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec5ffba7",
      "metadata": {
        "id": "ec5ffba7"
      },
      "source": [
        "This page is a hosted Jupyter notebook. This is a special tooks that allows to write a page with text and illustration but also to run specific code and see the result of your own code. This facility is made available by Google Colab, and provides this convenient space to learn deep learning or other machine learning techniques.\n",
        "\n",
        "\n",
        "**Step by step instructions**:\n",
        "1. You got to this page. You have started a notebook in read only mode. You can run it but if you make changes, you will not be able to save them. In the `File` menu, you should see command `Save a copy in Drive`. Select that command and it will create a copy of this notebook in a new window and also save it under your own gdrive. The default name will be `dl-guided-deep-dive-01-cv.ipynb` but you can change it at any time. This is **your version of the notebook**, You can run it and modify it.\n",
        "\n",
        "2. You have your own copy of the notebook and can run/execute code in it. One of the advantages of Colab is that you have access to GPU computing capabilities (useful to accelerate computer vision models). To get the GPU, see `Change runtime type` in the `Runtime` menu. Select GPU if it is not already done.\n",
        "\n",
        "    > Once your new notebook is active, you have access to your own computing and storage capacity on a computer in the cloud. It is available to you for a few hours and will stay active unless you do not do anything for 15-30 min or so."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qMyORPPfGGRi",
      "metadata": {
        "id": "qMyORPPfGGRi"
      },
      "source": [
        "#### üîé End of details"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce901f43",
      "metadata": {
        "id": "ce901f43"
      },
      "source": [
        "# üß∞ Imports and configurations\n",
        "Run the cells in this section to get ready. Do not worry about the code here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3EciXFUIidfC",
      "metadata": {
        "id": "3EciXFUIidfC"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from nb_guided_dive.vision import *\n",
        "except ModuleNotFoundError:\n",
        "    print('installing nb_guided_dive')\n",
        "    !pip install -Uqq git+https://github.com/vtecftwy/nb-guided-dive.git\n",
        "    print('nb_guided_dive installed')\n",
        "    from nb_guided_dive.vision import *\n",
        "try:\n",
        "    from ddgs import DDGS\n",
        "except ModuleNotFoundError:\n",
        "    print('installing ddgs')\n",
        "    !pip install -Uqq ddgs\n",
        "    print('ddgs installed')\n",
        "    from ddgs import DDGS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kbOfNDj2wp78",
      "metadata": {
        "id": "kbOfNDj2wp78"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import warnings\n",
        "# from duckduckgo_search import DDGS\n",
        "# from ddgs import DDGS\n",
        "from fastprogress.fastprogress import progress_bar\n",
        "from jmd_imagescraper.imagecleaner import display_image_cleaner\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from shutil import rmtree\n",
        "from fastai import __version__\n",
        "from fastai.vision.all import *\n",
        "from fastai.vision.utils import download_images\n",
        "from fastai.vision.widgets import ImagesCleaner , ImageClassifierCleaner\n",
        "\n",
        "# warnings.filterwarnings(\"ignore\", module=\"datetime\")\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "print(f\"fastai version {__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5jtusrDfBVCA",
      "metadata": {
        "id": "5jtusrDfBVCA"
      },
      "outputs": [],
      "source": [
        "config_fastai_for_colab()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24e8e15d",
      "metadata": {
        "id": "24e8e15d"
      },
      "source": [
        "# üì∑ Computer Vision: Steps to Build an Image Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64fa7c1f",
      "metadata": {
        "id": "64fa7c1f"
      },
      "outputs": [],
      "source": [
        "ml_process()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6609991f",
      "metadata": {
        "id": "6609991f"
      },
      "source": [
        "## 1Ô∏è‚É£ Framing the problem"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f3cd0bc",
      "metadata": {
        "id": "2f3cd0bc"
      },
      "source": [
        "Before building a solution, we must clearly define the problem to ensure we focus on the right objectives. We will explore this in detail in a lecture, but for now, let's outline the key points:  \n",
        "\n",
        "- Every day, a large number of **lemons** need to be shipped.  \n",
        "- Currently, lemons are **manually sorted** on a conveyor belt.  \n",
        "- The goal is to **automate** this process by adding a **camera** above the conveyor belt.  \n",
        "- The system will analyse images and classify each lemon as **OK** or **NOT OK**.  \n",
        "\n",
        "This setup will help streamline the sorting process and reduce manual labour."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb45ec2c",
      "metadata": {
        "id": "bb45ec2c"
      },
      "source": [
        "### **What We Have**  \n",
        "\n",
        "- A **conveyor belt** for transporting lemons.  \n",
        "- A **camera system** that can be installed above the belt to capture images of the lemons.  \n",
        "- A **sorting system** that can receive signals to reroute any lemons deemed **bad**.  \n",
        "\n",
        "With these components, we can automate the process of sorting lemons based on quality."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c78261bb",
      "metadata": {
        "id": "c78261bb"
      },
      "source": [
        "### **What could be a problem here?**\n",
        "\n",
        "üë∑ Think of this question and write your answer in the text cell below."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b34b2e3",
      "metadata": {
        "id": "5b34b2e3"
      },
      "source": [
        "[Double click here to edit this cell and and write your ideas.]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a521ce39",
      "metadata": {
        "id": "a521ce39"
      },
      "source": [
        "### **Stating the Problem as a Machine Learning Task**  \n",
        "- What inputs can we give the DL system?\n",
        "- What \"decision\" or prediction de we expect to get from the DL system?\n",
        "- What type of ML problem is it?\n",
        "- Type of data we need to feed the DL model?\n",
        "- What type of performance do we want to achieve? Is ther a minimum performance threshold to reach to succeed?\n",
        "---\n",
        "üë∑ Think of this and write your ideas below"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "483f362c",
      "metadata": {
        "id": "483f362c"
      },
      "source": [
        "[Double click here to edit this cell and and write your ideas.]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Rn4CFVkbcRb1",
      "metadata": {
        "id": "Rn4CFVkbcRb1"
      },
      "source": [
        "<details>\n",
        "<summary><b>A possible answer</b></summary>\n",
        "<ul>\n",
        "<li><p><b>What inputs can we give the DL system?</b></p>\n",
        "  <p>The inputs will be <b>images</b> of lemons captured by the camera system on the conveyor belt. These images will serve as the data fed into the deep learning model for analysis.</p>\n",
        "</li>\n",
        "<li><p><b>What \"decision\" or prediction do we expect to get from the DL system?</b></p>\n",
        "  <p>The system should predict whether each lemon is \"OK\" (good quality) or \"NOT OK\" (bad quality), based on the visual features of the lemon in the image.</p>\n",
        "</li>\n",
        "<li><p><b>What type of ML problem is it?</b></p>\n",
        "  <p>This is a binary classification problem, where the model must classify the lemons into one of two categories: \"OK\" or \"NOT OK\".</p>\n",
        "</li>\n",
        "<li><p><b>What type of data do we need to feed the DL model?</b></p>\n",
        "  <p>We need labeled images of lemons, where each image is marked as either \"OK\" or \"NOT OK\" based on the quality of the lemon.</p>\n",
        "</li>\n",
        "<li><p><b>What type of performance do we want to achieve? Is there a minimum performance threshold to reach to succeed?</b></p>\n",
        "  <p>We aim for a high classification accuracy, ideally above 95%, but a minimum threshold of 90% accuracy could be acceptable, depending on the specific requirements of the sorting process (e.g., how many bad lemons can be missed without affecting the overall process). Performance can also be evaluated using metrics like precision, recall, and F1-score to balance false positives and false negatives.  \n",
        "</li>\n",
        "</ul>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8fcaf7c",
      "metadata": {
        "id": "d8fcaf7c"
      },
      "source": [
        "## 2Ô∏è‚É£ Collect and Prepare Data, including Labeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "028a1cd5",
      "metadata": {
        "id": "028a1cd5"
      },
      "outputs": [],
      "source": [
        "ml_process()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d51ed498",
      "metadata": {
        "id": "d51ed498"
      },
      "source": [
        "To solve our ML problem, we need a dataset with the following information:\n",
        "- a set of images with lemons of good quality\n",
        "- a set of images with lemons that show quality problems (rot, ...)\n",
        "\n",
        "We should have between roughly 50 and 100 images for each set. We will need to clean up and delete some images from our set, it is safer to start with **100 or 150** images."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ed9d4bc",
      "metadata": {
        "id": "5ed9d4bc"
      },
      "source": [
        "### Collect images from internet\n",
        "\n",
        "Quickest and simplest way to create an initial image dataset is to collect them online.\n",
        "- Search images with key words or search phrases.\n",
        "- Download images and organize them in classes/categories based on the searches.\n",
        "- üëç : easy and fast. labeling is straigthforward if search well defined\n",
        "- üëé : quality of the images depends of the quality of the search engine and the search phrases.\n",
        "\n",
        "Good for a baseline, and to explore how things work out. Then we will need to improve."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e0d9ba3",
      "metadata": {
        "id": "4e0d9ba3"
      },
      "source": [
        "We will use [duckduckgo](https://duckduckgo.com/) search engine which provides good results and is easily reachable.\n",
        "><a href=\"https://duckduckgo.com\" target=\"_blank\"><img src=\"https://duckduckgo.com/assets/common/dax-logo.svg\" width=5%></a>\n",
        "\n",
        "We will do the following:\n",
        "1. Experiment directly on [duckduckgo](https://duckduckgo.com/) to craft a good search phrase for each class\n",
        "2. Use these two search phrases to scrape images and download them onto the server for furtehr use"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0902b73",
      "metadata": {
        "id": "a0902b73"
      },
      "source": [
        "#### Experiment with keywords\n",
        "\n",
        "Experiment on [duckduckgo](https://duckduckgo.com/) directly.\n",
        "\n",
        "The objective is to define one **search phrase** that generates a good set of images for lemons of good quality and one **search phrase** that generates a good set of images of lemons of poor quality. You will notice, for instance, that the search phrase `good lemons` will return lots of images with lemons that are cut üôÅ.\n",
        "\n",
        "For this simple exercise, select **one** search phrase for the class `good` and **one** search phrase for the class `bad`. In practice we would conbine the results of several search phrases for each class.\n",
        "\n",
        "Do not worry if you get a few unrelated images, we will clean this up later."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93e0448e",
      "metadata": {
        "id": "93e0448e"
      },
      "source": [
        "#### Launch the scraper application\n",
        "Once you have a good phrase for each of our two classes, save them in the cell below for further use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2865c0e",
      "metadata": {
        "id": "c2865c0e"
      },
      "outputs": [],
      "source": [
        "# Replace the phrase in red below by your phrase. Keep the appostrophes \" \"\n",
        "search_phrase_0 = \"write your search phrase here\"\n",
        "search_phrase_1 = \"write your search phrase here\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-L2grp_Xnqjw",
      "metadata": {
        "id": "-L2grp_Xnqjw"
      },
      "outputs": [],
      "source": [
        "search_phrase_0 = \"lemon rotten uncut\"\n",
        "search_phrase_1 = \"images of entire uncut lemons of good quality\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "J911Dzj0s6he",
      "metadata": {
        "id": "J911Dzj0s6he"
      },
      "source": [
        "<details>\n",
        "<summary>Tips if you are stuck:</summary>\n",
        "<p><code>search_phrase_0 = \"lemon rotten\"</code></p>\n",
        "<p><code>search_phrase_1 = \"images of entire lemons of good quality\"</code></p>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uI-UAL2BLO57",
      "metadata": {
        "id": "uI-UAL2BLO57"
      },
      "source": [
        "Give a name for each of your classes. The simple implementation in this exercise require that the class name does not include spaces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZNNhhAYuLHHD",
      "metadata": {
        "id": "ZNNhhAYuLHHD"
      },
      "outputs": [],
      "source": [
        "class_name_0 = \"bad\"  # for class 0 in the binary classifier\n",
        "class_name_1 = \"good\"   # for class 1 in the binary classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78a672f6",
      "metadata": {
        "id": "78a672f6"
      },
      "source": [
        "Pick a number of images to download for each class. You can define between 50 and 450 images to download for each class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7c12017",
      "metadata": {
        "id": "f7c12017"
      },
      "outputs": [],
      "source": [
        "number_images_to_download = 100         # this can go up to 450 at the time of writing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa7eafab",
      "metadata": {
        "id": "fa7eafab"
      },
      "source": [
        "The cells below will automate the search and download process for you. It will:\n",
        "- create a path to the folder where we want the images to be saved\n",
        "- run the DuckDuckGo search for the two classes\n",
        "- check that all images are correctly downloaded and delete any corrupted images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98Bym-Y5mH3C",
      "metadata": {
        "id": "98Bym-Y5mH3C"
      },
      "outputs": [],
      "source": [
        "def get_images(keywords, label, path, max_results=100):\n",
        "    \"\"\"Retrieve images search results based on a list of keywords\"\"\"\n",
        "    results = DDGS().images(\n",
        "        query=keywords,\n",
        "        region=\"wt-wt\",\n",
        "        safesearch=\"on\",\n",
        "        size=None,\n",
        "        color=\"color\",\n",
        "        type_image='photo',\n",
        "        layout=None,\n",
        "        license_image=None,\n",
        "        max_results=max_results,\n",
        "    )\n",
        "    if len(results) == 0:\n",
        "        print(f\"Not images found for {keywords}\")\n",
        "    else:\n",
        "        path2imgs = path / label\n",
        "        os.makedirs(path2imgs, exist_ok=True)\n",
        "        urls = [r['image'] for r in results]\n",
        "        print(f\"Found {len(results)} images for label {label}. Downloading into {path2imgs.absolute()}\")\n",
        "        download_images(path2imgs, urls=urls)\n",
        "        print('All downloaded')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "msla7gI33nE3",
      "metadata": {
        "id": "msla7gI33nE3"
      },
      "outputs": [],
      "source": [
        "def clean_image_directory(path, verbose=False):\n",
        "    \"\"\"Check all image files in the directory and removes any image that cannot be loaded\"\"\"\n",
        "    def check_img(img):\n",
        "        try: _ = Image.open(img)\n",
        "        except Exception as e:\n",
        "            img = str(img).replace(\" \",\"\\ \")\n",
        "            os.system(f\"rm -f {img}\");\n",
        "            print(f\"removing error img:{img}\")\n",
        "\n",
        "    for cls in path.iterdir():\n",
        "        for i, img in enumerate(cls.iterdir()):\n",
        "            if verbose: print(i, end=' - ')\n",
        "            check_img(img)\n",
        "            if verbose: print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1QCuhfexGTS",
      "metadata": {
        "id": "f1QCuhfexGTS"
      },
      "outputs": [],
      "source": [
        "# Use this cell if you want to delete the image directory and all images\n",
        "# rmtree('/content/images')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf685cce",
      "metadata": {
        "id": "bf685cce"
      },
      "outputs": [],
      "source": [
        "path = Path()/ 'images'\n",
        "print(f\"All images will be saved into {path.absolute()}\")\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# Search and download\n",
        "get_images(keywords=search_phrase_0, label=class_name_0, path=path, max_results=number_images_to_download)\n",
        "get_images(keywords=search_phrase_1, label=class_name_1, path=path, max_results=number_images_to_download)\n",
        "\n",
        "# Check that all images can be used and delete any defective image\n",
        "clean_image_directory(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kJxqK0sXL7Ia",
      "metadata": {
        "id": "kJxqK0sXL7Ia"
      },
      "outputs": [],
      "source": [
        "count_files(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TrrRLERvq1j3",
      "metadata": {
        "id": "TrrRLERvq1j3"
      },
      "source": [
        "Why is the number of images not 100 for each class?\n",
        "- some images were deleted because we could not open the file\n",
        "- several links in the search results may have pointed to the same image file"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4781ff1",
      "metadata": {
        "id": "d4781ff1"
      },
      "source": [
        "We have downloaded our images into a folder called `images`.\n",
        "\n",
        "If you explore the file tree below `images`, you will note that:\n",
        "- all images for good lemons are grouped into `images/good`\n",
        "- all images for bad lemons are grouped into `images/bad`\n",
        "\n",
        "This is a common way to organize image datasets for classification. One directory grouping all images of one class."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8BJFT6Engsg2",
      "metadata": {
        "id": "8BJFT6Engsg2"
      },
      "source": [
        "üëç Now we are ready to start with the model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d87349e",
      "metadata": {
        "id": "3d87349e"
      },
      "source": [
        "### Prepare data to feed the model.\n",
        "Computer only do what they are told to do, therefore we need to tell it:\n",
        "- what type of data we will use,\n",
        "- where it can find the data (images), and\n",
        "- what to do with it.\n",
        "\n",
        "We do that with a **`DataBlock`**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WTWA4HaTC9VE",
      "metadata": {
        "id": "WTWA4HaTC9VE"
      },
      "source": [
        "\n",
        "\n",
        "In this example, the code below tells the computer:\n",
        "- we have **images** as input\n",
        "- all images files are in a specific folder\n",
        "    - the computer retrieves images by using a function **`get_image_files`** which returns a list of all the images in a given folder\n",
        "- for each image, we have one *label* a.k.a. *class* a.k.a **`category`** a.k.a. **`y`**\n",
        "    - the computer will know which is the class of each image by looking in which **folder** it is located\n",
        "    - this is retrieved by using a function **`parent_label`**\n",
        "- before using each image, the computer should **resize** it into a standard square of size 128 pixels\n",
        "- finaly, we want to keep a **validation set** of 30% of the images. These images will **not** be used for training, but they are only used to test whether the trained model generalizes well on new images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JtUzLJBXrHEw",
      "metadata": {
        "id": "JtUzLJBXrHEw"
      },
      "outputs": [],
      "source": [
        "fn_list = get_image_files(path)\n",
        "fn_list[:3], fn_list[-3:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ZtU2VXjrSKm",
      "metadata": {
        "id": "9ZtU2VXjrSKm"
      },
      "outputs": [],
      "source": [
        "parent_label(fn_list[0]), parent_label(fn_list[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ce8654a",
      "metadata": {
        "id": "2ce8654a"
      },
      "outputs": [],
      "source": [
        "dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
        "                   get_items=get_image_files,\n",
        "                   get_y=parent_label,\n",
        "                   item_tfms=Resize(128),\n",
        "                   splitter=RandomSplitter(valid_pct=0.10, seed=88),\n",
        "                   )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "340ebeb1",
      "metadata": {
        "id": "340ebeb1"
      },
      "source": [
        "Now the computer has a **recipe** to handle images in a specific folder. It has not done anything yet.\n",
        "\n",
        "We have put our images in `path`. Now we tell the computer to apply the recipe (`dblock`) to a specific folder (`path`):\n",
        "- go to `path`\n",
        "- identify all images there\n",
        "- build a dataset for training and a dataset for validation\n",
        "- get ready to resize the data\n",
        "- use the images in groups of 16 at the time\n",
        "\n",
        "What we get after that is called a **`dataloaders`** (`dls`) because it is the tool the computer will use to load data into the model. It is plural because there are two sets: training and validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gpdufqnLzXsB",
      "metadata": {
        "id": "gpdufqnLzXsB"
      },
      "outputs": [],
      "source": [
        "path.absolute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d37cd336",
      "metadata": {
        "id": "d37cd336"
      },
      "outputs": [],
      "source": [
        "dls = dblock.dataloaders(path, bs=16)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b56a7ef",
      "metadata": {
        "id": "2b56a7ef"
      },
      "source": [
        "The `dataloaders` `dls` gives us access to all images. One thing we can do is to see a random sample of the images and their labels. We can play with the number of images to display (`max_n`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db656e8e",
      "metadata": {
        "id": "db656e8e"
      },
      "outputs": [],
      "source": [
        "dls.show_batch(max_n=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c36d67b7",
      "metadata": {
        "id": "c36d67b7"
      },
      "source": [
        "### Clean up data\n",
        "Some of the images are not what we want, or are wrongly labeled. We can correct or remove them."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EEYmDg4dDBhc",
      "metadata": {
        "id": "EEYmDg4dDBhc"
      },
      "source": [
        "Looking above, it clear that some of the images are not correct or not optimum for training. We need to delete some of them.\n",
        "- images with something not related to the class (e.g. other item then lemon on the photo, ...)\n",
        "- images that are drawings and not real photos\n",
        "- multiple faces, ...\n",
        "\n",
        "It is a judgment call, there is no formal rule for that. Use common sense.\n",
        "\n",
        "To make this easier, we will use a tool called `display_image_cleaner`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23146127",
      "metadata": {
        "id": "23146127"
      },
      "outputs": [],
      "source": [
        "display_image_cleaner(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62t8JVW5Rxz0",
      "metadata": {
        "id": "62t8JVW5Rxz0"
      },
      "outputs": [],
      "source": [
        "count_files(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93db0e12",
      "metadata": {
        "id": "93db0e12"
      },
      "source": [
        "#### Update our `dataloaders`\n",
        "Our data are now cleaned up a little. We recreate our dataloaders, because we have deleted some images and it is important to refresh it all."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7eb00453",
      "metadata": {
        "id": "7eb00453"
      },
      "outputs": [],
      "source": [
        "dls = dblock.dataloaders(path, bs=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b92b5d50",
      "metadata": {
        "id": "b92b5d50"
      },
      "source": [
        "Let's have a look at the images again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e837a175",
      "metadata": {
        "id": "e837a175"
      },
      "outputs": [],
      "source": [
        "dls.show_batch(max_n=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac90f4cc",
      "metadata": {
        "id": "ac90f4cc"
      },
      "source": [
        "OK, this looks good enough for a first training run now."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2df5a18",
      "metadata": {
        "id": "b2df5a18"
      },
      "source": [
        "## 3Ô∏è‚É£ Build a model and train it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc2e6a48",
      "metadata": {
        "id": "dc2e6a48"
      },
      "outputs": [],
      "source": [
        "ml_process()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f0c4594",
      "metadata": {
        "id": "1f0c4594"
      },
      "source": [
        "We are ready to build the model.\n",
        "\n",
        "We will not build a neural network from scratch. Instead, we will use a **pre-trained models** and perform something called **transfer learning**.\n",
        "\n",
        "We use a model that has been trained on a very large number of images to solve a specific classification problem, and then we will finetune it for our own classification problem.\n",
        "\n",
        "Sounds like a big thing, but we will do this in two lines of code with `fastai`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-N0E3pR9GwZF",
      "metadata": {
        "id": "-N0E3pR9GwZF"
      },
      "source": [
        "#### Architecture Selection\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Kd_kv_OkG0mE",
      "metadata": {
        "id": "Kd_kv_OkG0mE"
      },
      "source": [
        "We select: RESNET 18.\n",
        "> Resnet is a SOTA convolutional neural network (CNN), pre-trained on a large dataset called Imagenet, including 1,281,167 training images organized in 1,000 classes.\n",
        ">\n",
        "><img src=\"https://image-net.org/static_files/index_files/logo.jpg\" height=20px>\n",
        ">\n",
        "> CNNs are the currently go-to type of architectures for computer vision problem and Resnet is an excellent choice. Resnet comes in several versions, including\n",
        "> - resnet-18 with 18 layers\n",
        "> <div align=\"center\"><img src=\"https://www.charlier-tang.com/guided-dive/resources/imgs/resnet-18-01.png\" width=75%></div>\n",
        "> - resnet-34 with 34 layers\n",
        "> <div align=\"center\"><img src=\"https://www.charlier-tang.com/guided-dive/resources/imgs/resnet-34-01.png\" height=300px></div>\n",
        "> - resnet-50 with 50 layers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8f0f92b",
      "metadata": {
        "id": "a8f0f92b"
      },
      "source": [
        "#### Create a model CNN model for computer vision\n",
        "We create the model by telling the computer:\n",
        "- the **data** to use to train the model: `dls`\n",
        "- the **architecture** to use: `resnet18`. you can experiment with `resnet34` or `resnet50`.\n",
        "- the **metrics** we want to monitor to evaluate the performance. We will use the **accuracy**, **precision** and **recall**. More in this later\n",
        "\n",
        "The first time we run the cell, fastai will download the pretrained model parameters to use them. After that it will use the copy it has saved on disk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c02b85a9",
      "metadata": {
        "id": "c02b85a9"
      },
      "outputs": [],
      "source": [
        "learn = vision_learner(\n",
        "    dls,\n",
        "    resnet18,\n",
        "    metrics=[accuracy, Precision(), Recall()]\n",
        "    );"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "278170f8",
      "metadata": {
        "id": "278170f8"
      },
      "source": [
        "#### Train - Finetune the model\n",
        "\n",
        "Now we are ready to train our model (`learner`).  As we use a pretrained model, we will **finetune** it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sHMKIfpxT5hk",
      "metadata": {
        "id": "sHMKIfpxT5hk"
      },
      "source": [
        "How does the model learn? Three levels of explanation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ouEZnMzAT4X6",
      "metadata": {
        "id": "ouEZnMzAT4X6"
      },
      "source": [
        "###### Level 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FxDEeEfzUIAU",
      "metadata": {
        "id": "FxDEeEfzUIAU"
      },
      "source": [
        "The model learns by \"looking\" at each image several times and modifying its parameters to improve the match between its predicted outputs and the training labels.\n",
        "\n",
        "It is essentially an iterative optimization problem: what is the combination of parameter values that results to the best accuracy between predicted classes and labels (true class) across the training dataset and the validation dataset.\n",
        "\n",
        "When we have a model that shows good performances (training and validation accuracy), we \"hope\" that it has **generalized**. This means that it will also perform well on all new data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8po3ow4zUkYU",
      "metadata": {
        "id": "8po3ow4zUkYU"
      },
      "source": [
        "###### Level 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "I1KBf3LiWyTJ",
      "metadata": {
        "id": "I1KBf3LiWyTJ"
      },
      "source": [
        "The optimization process used for deep learning models is based on an iteration of **forward pass** and **back propagation pass**.\n",
        "\n",
        " <div align=\"center\"><img src=\"https://www.charlier-tang.com/guided-dive/resources/imgs/backpropagation-2.gif\" width=50%></div>\n",
        "\n",
        "- Take a number of images out of the training dataset (in our case 16), called a batch\n",
        "    - forward pass:\n",
        "        - calculate a prediction for image in this batch\n",
        "        - evaluate how remote the predictions are compared to the label provided in the training set (loss)\n",
        "    - back propagation pass:\n",
        "        - adjust all parameters to come closer to the correct prediction for all images in the batch, using the loss and its gradient w.r.t. each parameter.\n",
        "- Start again, until all images are seen."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JTPWoMrZUnLl",
      "metadata": {
        "id": "JTPWoMrZUnLl"
      },
      "source": [
        "-"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iXzxJZjIUoWM",
      "metadata": {
        "id": "iXzxJZjIUoWM"
      },
      "source": [
        "###### Level 3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QahN4NlTbXN1",
      "metadata": {
        "id": "QahN4NlTbXN1"
      },
      "source": [
        "There are many options available to train a model, and the choice of these options will make the model train well or not. A good model will train well as it achieves good performances on the training and validation sets (generalizes).\n",
        "<div align=\"center\"><img src=\"https://www.charlier-tang.com/guided-dive/resources/imgs/overfit-underfit.png\" width=70%></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rNZ3G8aFKHlx",
      "metadata": {
        "id": "rNZ3G8aFKHlx"
      },
      "source": [
        "**Key options**:\n",
        "\n",
        "- Learning the best parameters is an optimization problem: define the parammeters which minimize the loss function\n",
        "<div align=\"center\"><img src=\"https://www.charlier-tang.com/guided-dive/resources/imgs/sgd-1.png\" width=70%></div>\n",
        "\n",
        "\n",
        "- There are several optimizer algorithms available for training. Some are faster, some are less prone to fall in \"local minima\".\n",
        "<div align=\"center\"><img src=\"https://www.charlier-tang.com/guided-dive/resources/imgs/optimizers-2.gif\" width=50%></div>\n",
        "\n",
        "\n",
        "- The single most important factor for training, beside the optimizer, is the Learning Rate\n",
        "<div align=\"center\"><img src=\"https://www.charlier-tang.com/guided-dive/resources/imgs/lr.png\" width=80%></div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZkJB_iuqa1H2",
      "metadata": {
        "id": "ZkJB_iuqa1H2"
      },
      "source": [
        "###### Training vs Finetuning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ofCn2CVIULzs",
      "metadata": {
        "id": "ofCn2CVIULzs"
      },
      "source": [
        "While training, the model \"sees\" all images in the training set, several times.\n",
        "\n",
        "In deep learning jargon, one iteration over which the model sees all images in the training set once is called an **`epoch`**.\n",
        "\n",
        "When models are trained from scratch, it is often necessary to use hundred or thousands of epochs. But in the case of a pre-trained model, a few epochs are often enough in first instance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PpmKOqVKK4kk",
      "metadata": {
        "id": "PpmKOqVKK4kk"
      },
      "source": [
        "We run 5 or 10 epochs. But fee free to try less or more\n",
        "\n",
        "At the end of each epoch, the system returns information of the metrics:\n",
        "\n",
        "|epoch|train_loss|valid_loss|accuracy|precision_score|recall_score|time\n",
        "|-----|----------|----------|--------|---------------|------------|----\n",
        "0|1.081642|0.391084|0.833333|0.818182|0.818182|00:01\n",
        "\n",
        "Accuracy, Precision and Recall are the three metrics we will follow. The closet to one the better."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "shi04SoCfPIV",
      "metadata": {
        "id": "shi04SoCfPIV"
      },
      "source": [
        "Learning Rate (`lr`) is the single most important optimization parameter. It is the \"speed\" at which or \"extend\" to which the model correct itself at each iteration/pass. High learning rate train fast but also lead to divergence. Low learning rate make training very slow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7N0y8iCeOTm",
      "metadata": {
        "id": "f7N0y8iCeOTm"
      },
      "outputs": [],
      "source": [
        "lr = learn.lr_find(suggest_funcs=(SuggestionMethod.Valley, SuggestionMethod.Minimum, SuggestionMethod.Slide, SuggestionMethod.Steep))\n",
        "lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fIWnysSstG9i",
      "metadata": {
        "id": "fIWnysSstG9i"
      },
      "outputs": [],
      "source": [
        "learn = vision_learner(\n",
        "    dls,\n",
        "    resnet18,\n",
        "    metrics=[accuracy, Precision(), Recall()]\n",
        "    );"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5187ff3",
      "metadata": {
        "id": "c5187ff3"
      },
      "outputs": [],
      "source": [
        "nr_epochs = 10\n",
        "\n",
        "learn.fine_tune(nr_epochs, freeze_epochs=2, base_lr=lr.valley)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e05b97c4",
      "metadata": {
        "id": "e05b97c4"
      },
      "source": [
        "How good is our model? The metrics have improved during training, but is the final result a good one?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ir9L4ybcP2bL",
      "metadata": {
        "id": "Ir9L4ybcP2bL"
      },
      "outputs": [],
      "source": [
        "learn.recorder.plot_loss();"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "194924ae",
      "metadata": {
        "id": "194924ae"
      },
      "source": [
        "## 4Ô∏è‚É£ Evaluate the trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64901558",
      "metadata": {
        "id": "64901558"
      },
      "outputs": [],
      "source": [
        "ml_process()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52881f31",
      "metadata": {
        "id": "52881f31"
      },
      "source": [
        "### Evaluate based on the validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edb752e3",
      "metadata": {
        "id": "edb752e3"
      },
      "source": [
        "We have reserved about 30% of the images for `validation`, with is checking how the model performs on images it has not seen during training. If the model **generalizes**, the result of these images should be good as well.\n",
        "\n",
        "One good tool to evalute the model is to plot the confusion matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f9a69cf",
      "metadata": {
        "id": "3f9a69cf"
      },
      "outputs": [],
      "source": [
        "interp = ClassificationInterpretation.from_learner(learn)\n",
        "interp.plot_confusion_matrix()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kJ_902xfm2jm",
      "metadata": {
        "id": "kJ_902xfm2jm"
      },
      "outputs": [],
      "source": [
        "cm = interp.confusion_matrix()\n",
        "print_metrics(cm, class_0=class_name_0, class_1=class_name_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f31879b",
      "metadata": {
        "id": "5f31879b"
      },
      "source": [
        "We also can visualize the images where we have errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28f52dec",
      "metadata": {
        "id": "28f52dec"
      },
      "outputs": [],
      "source": [
        "interp.plot_top_losses(k=6)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "079f366c",
      "metadata": {
        "id": "079f366c"
      },
      "source": [
        "### Evaluate with new data\n",
        "\n",
        "We only had a small set of unseen images (validation set).\n",
        "\n",
        "We should use a larger test set. We could download more images and create a bigger test set. But it hapens that there is a lemon dataset on Kaggle, which I have made available on AWS S3 for download.  It includes more than 2,000 labelled images. Let's use a subset of these to use as test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZLIgNwr8vY5f",
      "metadata": {
        "id": "ZLIgNwr8vY5f"
      },
      "outputs": [],
      "source": [
        "path_to_ds = untar_data('https://diyai-dives.s3.ap-southeast-1.amazonaws.com/datasets/lemon-img-ds.zip')\n",
        "path_to_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aJqUWWS-wlp9",
      "metadata": {
        "id": "aJqUWWS-wlp9"
      },
      "outputs": [],
      "source": [
        "for p in path_to_ds.ls():\n",
        "    if 'quality' not in p.name: rmtree(p)\n",
        "    if 'quality' in p.name: shutil.move(p, p.parent / f\"{p.name.replace('_quality','')}\")\n",
        "\n",
        "path_to_ds.ls()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TgS5LC9bS0WE",
      "metadata": {
        "id": "TgS5LC9bS0WE"
      },
      "outputs": [],
      "source": [
        "# rmtree(path_to_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c61f7bc",
      "metadata": {
        "id": "5c61f7bc"
      },
      "outputs": [],
      "source": [
        "test_path = path_to_ds\n",
        "count_files(test_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ba24f74",
      "metadata": {
        "id": "1ba24f74"
      },
      "source": [
        "The code below randomly selects a small number of images from the huge dataset to use as a test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61bd03b0",
      "metadata": {
        "id": "61bd03b0"
      },
      "outputs": [],
      "source": [
        "nbr_test_images = 100\n",
        "\n",
        "test_image_fnames = get_image_files(test_path)\n",
        "idxs = np.random.choice(len(test_image_fnames)-1, nbr_test_images)\n",
        "test_image_fnames = test_image_fnames[idxs]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8549e3a5",
      "metadata": {
        "id": "8549e3a5"
      },
      "source": [
        "#### Create the test set\n",
        "Now we create a test dataset. To do so, we use the same dataloaders`dls` as before, but we tell the computer to look at the images from the list of image file names `test_image_fnames`, and to perform the same type of actions (recipe) as for the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8cd2cce",
      "metadata": {
        "id": "c8cd2cce"
      },
      "outputs": [],
      "source": [
        "test_dl = dls.test_dl(test_image_fnames, with_labels=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff8c9a6f",
      "metadata": {
        "id": "ff8c9a6f"
      },
      "outputs": [],
      "source": [
        "test_dl.show_batch(max_n=16)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8GCOv9BTLxMh",
      "metadata": {
        "id": "8GCOv9BTLxMh"
      },
      "source": [
        "#### Predict and evaluate the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb1abbac",
      "metadata": {
        "id": "cb1abbac"
      },
      "source": [
        "Now we do the interpretation again, but using the test dataloader `test_dl`, instead of the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09258b9e",
      "metadata": {
        "id": "09258b9e"
      },
      "outputs": [],
      "source": [
        "test_results = learn.validate(dl=test_dl)\n",
        "for i, m in enumerate(learn.metrics):\n",
        "    print(f\"{m.name:16s}:  {test_results[i+1]*100:.1f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "912bd426",
      "metadata": {
        "id": "912bd426"
      },
      "outputs": [],
      "source": [
        "interp_test = ClassificationInterpretation.from_learner(learn, dl=test_dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01af4380",
      "metadata": {
        "id": "01af4380"
      },
      "outputs": [],
      "source": [
        "interp_test.plot_confusion_matrix()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5dd7516f",
      "metadata": {
        "id": "5dd7516f"
      },
      "source": [
        "**What to watch**:\n",
        "- Do we not let pass many bad lemons ?\n",
        "\n",
        "- Do we block many good lemons ? What is the impact on costs üí£ !"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7530c5df",
      "metadata": {
        "id": "7530c5df"
      },
      "source": [
        "Let's have a look at the biggest mistakes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "021147c7",
      "metadata": {
        "id": "021147c7"
      },
      "outputs": [],
      "source": [
        "interp_test.plot_top_losses(k=9, figsize=(10, 10))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cf080c5",
      "metadata": {
        "id": "9cf080c5"
      },
      "source": [
        "It is clear that the model misses quite a few cases when the image is not that good. But a good model should be able to see that, we, humans, can."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20fe5e33",
      "metadata": {
        "id": "20fe5e33"
      },
      "source": [
        "## 5Ô∏è‚É£ Improve the model by using more data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6f263a3",
      "metadata": {
        "id": "c6f263a3"
      },
      "outputs": [],
      "source": [
        "ml_process()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3435d6e4",
      "metadata": {
        "id": "3435d6e4"
      },
      "source": [
        "We have seen that we can get a decent model with only between 50 and 100 images of each class. But we also saw that the result need improvement. The best way to get more out of the model is to feed it more data.\n",
        "\n",
        "We could download 400 images and clean these, and then retrain the model.\n",
        "\n",
        "But let's go crazy !\n",
        "\n",
        "We will use the **Lemon** dataset already available on Kaggle. With 2,000 images, we are going all the way toward large dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e25194f0",
      "metadata": {
        "id": "e25194f0"
      },
      "source": [
        "### Create the dataloaders\n",
        "\n",
        "This is exactly the same recipe as before, except that we set a vaidation set of 40% as we have more images in general."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18fcc5d3",
      "metadata": {
        "id": "18fcc5d3"
      },
      "outputs": [],
      "source": [
        "dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
        "                   get_items=get_image_files,\n",
        "                   get_y=parent_label,\n",
        "                   item_tfms=Resize(128),\n",
        "                   splitter=RandomSplitter(valid_pct=0.4, seed=42),\n",
        "                   )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23e33199",
      "metadata": {
        "id": "23e33199"
      },
      "source": [
        "Now we apply this \"recipe\" to all images in the folder that includes our big lemon image dataset. It will take a little while as there are many images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49bd8c86",
      "metadata": {
        "id": "49bd8c86"
      },
      "outputs": [],
      "source": [
        "dls = dblock.dataloaders(path_to_ds, bs=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acc07dc0",
      "metadata": {
        "id": "acc07dc0"
      },
      "outputs": [],
      "source": [
        "dls.show_batch(max_n=16)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b73f189",
      "metadata": {
        "id": "8b73f189"
      },
      "source": [
        "## Create a new model and train it\n",
        "\n",
        "Be prepared, training will take longer then before. We have close to 300 times more images. You can count on 2 to 4 minutes per epoch.\n",
        "\n",
        "It is longer, but as a comparison, a full training from scratch of resnet would take something like **14 days** on a normal GPU like we have here.\n",
        "\n",
        "We create a model like before and then finetune it for 5 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2e0af77",
      "metadata": {
        "id": "c2e0af77"
      },
      "outputs": [],
      "source": [
        "learn = vision_learner(\n",
        "    dls,\n",
        "    resnet18,\n",
        "    metrics=[accuracy, Precision(), Recall()]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HidIxIaRzu_r",
      "metadata": {
        "id": "HidIxIaRzu_r"
      },
      "outputs": [],
      "source": [
        "lr = learn.lr_find(suggest_funcs=[SuggestionMethod.Valley, SuggestionMethod.Minimum, SuggestionMethod.Slide, SuggestionMethod.Steep])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KakcJ7_rXlsE",
      "metadata": {
        "id": "KakcJ7_rXlsE"
      },
      "outputs": [],
      "source": [
        "learn.fine_tune(freeze_epochs=2, epochs=10, base_lr = lr.valley)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5Lqg04KN0FU-",
      "metadata": {
        "id": "5Lqg04KN0FU-"
      },
      "outputs": [],
      "source": [
        "learn.recorder.plot_loss();"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fdeb6a4",
      "metadata": {
        "id": "7fdeb6a4"
      },
      "source": [
        "### Evaluate the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3bdaf44",
      "metadata": {
        "id": "e3bdaf44"
      },
      "outputs": [],
      "source": [
        "interp = ClassificationInterpretation.from_learner(learn)\n",
        "interp.plot_confusion_matrix()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cdc13af",
      "metadata": {
        "id": "4cdc13af"
      },
      "source": [
        "üëç This is a much better performance. We still have a few mistakenly classified images but a much smaller percentage.\n",
        "\n",
        "We can expect much less complaints from management about wasting good lemons !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6848b79",
      "metadata": {
        "id": "f6848b79"
      },
      "outputs": [],
      "source": [
        "interp.plot_top_losses(k=4, figsize=(8, 8))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "939da5f4",
      "metadata": {
        "id": "939da5f4"
      },
      "source": [
        "# Final comments and next step"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5c699b5",
      "metadata": {
        "id": "a5c699b5"
      },
      "source": [
        "From here, there are many techniques to further improve and stress test the model. But this is beyond what we wanted you to experience during this session.\n",
        "\n",
        "The next steps, beside further improvement, will include:\n",
        "- saving the model so that it can be used by others\n",
        "- creating an application using the saved model and easiy classify new images.\n",
        "\n",
        "In our case, the application will be integrated into our existing temperature system and interface with the access control system. This is pure IT design, and will use the outcome of this discovery phase to build a strong and resilient model,"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5a0c380",
      "metadata": {
        "id": "a5a0c380"
      },
      "source": [
        "Do not forget to save your notebook before you close this window."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "d635b567",
        "50e0c1de",
        "90403b1e",
        "5873f103",
        "qMyORPPfGGRi",
        "bb45ec2c",
        "a0902b73",
        "ouEZnMzAT4X6",
        "8po3ow4zUkYU",
        "iXzxJZjIUoWM"
      ],
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 1341.270296,
      "end_time": "2021-09-12T09:20:50.567018",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-09-12T08:58:29.296722",
      "version": "2.3.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
